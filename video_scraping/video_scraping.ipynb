{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"name":"크롤링_다운로드.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"add3bda1"},"source":["from selenium import webdriver\n","import time\n","from bs4 import BeautifulSoup\n","import requests\n","\n","chrome_options = webdriver.ChromeOptions()\n","chrome_options.add_argument('--headless')\n","chrome_options.add_argument('--no-sandbox')\n","chrome_options.add_argument('--disable-dev-shm-usage')"],"id":"add3bda1","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f350cb2a","outputId":"9bad2a20-24d9-4b6a-d4cb-cd347f7b5f7f"},"source":["#전처리 부분\n","import pandas as pd\n","from datetime import datetime, timedelta\n","\n","#파일 받아오기\n","file = \"full_videos_list.csv\"\n","df=pd.read_csv(file)\n","\n","#컬럼명 지정\n","df.columns=['a','team','site']\n","\n","#team컬럼에 [다시보기]제거\n","df['team']=df['team'].str.replace('\\[다시보기\\] ','')\n","\n","#필요없는 컬럼 제거\n","df.drop(['a'],axis=1,inplace=True)\n","\n","#dh(더블헤더)컬럼 생성\n","def read_dh(s):\n","  if 'DH1' in s:\n","    return '1'\n","  elif 'DH2' in s:\n","    return '2'\n","  return '0' \n","\n","df['dh']=df['team'].apply(lambda x:read_dh(x))\n","\n","#team컬럼 형식 통일\n","df['team']=df['team'].str.replace('월_','월 ')\n","df['team']=df['team'].str.replace('일 ','월 ')\n","\n","#team컬럼 '_'기준으로 나눠서 날짜, 파일번호, 팀 컬럼 생성\n","df['date']=df['team'].str.split('_').str[1]\n","df['number']=df['team'].str.split('_').str[2]\n","df['team']=df['team'].str.split('_').str[0]\n","\n","#date컬럼 형식 통일\n","df['date']=df['date'].str.replace(' (DH1)','')\n","\n","#number컬럼 형식 통일\n","df['number']=df['number'].str.replace('부','')\n","\n","#team컬럼 형식을 예) 롯데 vs 삼성 으로 되있는걸 LTSS 이런 형식으로 통일\n","df['team']=df['team'].str.replace(' vs ','')\n","df['team']=df['team'].str.replace('롯데','LT')\n","df['team']=df['team'].str.replace('KIA','HT')\n","df['team']=df['team'].str.replace('키움','WO')\n","df['team']=df['team'].str.replace('두산','OB')\n","df['team']=df['team'].str.replace('SSG','SK')\n","df['team']=df['team'].str.replace('삼성','SS')\n","df['team']=df['team'].str.replace('한화','HH')\n","\n","#team컬럼 필요없는 부분 제거\n","df['team']=df['team'].str[:4]\n","\n","#날짜 형식 통일\n","df['mon']=df['date'].str.split('월 ').str[0]\n","df['day']=df['date'].str.split('월 ').str[1]\n","df['day']=df['day'].str.replace('일','')\n","\n","def change_date(s):\n","    if len(s)==1:\n","        return str('0'+s)\n","    else:\n","        return str(s)\n","    \n","df['mon']=df['mon'].apply(lambda x:change_date(x))\n","df['day']=df['day'].apply(lambda x:change_date(x))\n","df['date']='2021'+df['mon']+df['day']\n","df.drop(['mon','day'],axis=1,inplace=True)"],"id":"f350cb2a","execution_count":null,"outputs":[{"output_type":"stream","text":["<ipython-input-112-4bf360bee205>:7: FutureWarning: The default value of regex will change from True to False in a future version.\n","  df['team']=df['team'].str.replace('\\[다시보기\\] ','')\n","<ipython-input-112-4bf360bee205>:14: FutureWarning: The default value of regex will change from True to False in a future version.\n","  df['date']=df['date'].str.replace(' (DH1)','')\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"1e1548c9"},"source":["import urllib.request\n","import webbrowser\n","import os\n","\n","#driver생성\n","driver = webdriver.Chrome(\"c:/data/chromedriver\")#, options=chrome_options)\n","\n","#src가 블롭형식으로 되어있을 때 그 리스트를 받기 위해서 생성\n","blob=pd.DataFrame()\n","\n","#while문을 돌리기위해 i생성(시작점)\n","i=0\n","\n","#광고영상이 대신 다운받아지는것을 방지하기 위해 광고일 경우 50초(광고시간)를 기다렸다가 진행\n","t=0\n","\n","#i가 df의 길이 만큼 반복\n","while i < len(df):\n","    print(i)\n","    #df의 site칼럼에서 url받기\n","    baseUrl = df['site'][i]\n","    #driver실행\n","    driver.get(baseUrl)\n","    soup = BeautifulSoup(driver.page_source, \"html\")\n","    #실행된 site에서 영상 부분 태그\n","    v_url=soup.find('iframe',id='player_vod')['src']\n","    #주소에서 화질 변경 HIGH는 720 HIGH4는 1080\n","    v_url=v_url.replace('HIGH','HIGH4')\n","    #driver실행\n","    driver.get(v_url)\n","    #바로 src를 얻어오면 src가 생성이 되어있지않기 때문에 src가 생성될 수 있게 대기\n","    time.sleep(3)\n","    soup = BeautifulSoup(driver.page_source, \"html\")  \n","    #광고영상이 나오는 url인 경우 50초를 기다리고 아닌 경우 0초\n","    time.sleep(t)\n","    #src가 blob으로 되어있는 경우 blob df에 넣기 \n","    if 'blob' in soup.find('video',id='videoElement')['src']:\n","        blob=blob.append(df.loc[i])\n","    else:\n","        #print(soup.find('video',id='videoElement')['src'])\n","        start=time.time()\n","        print('start: ',start)\n","        #파일 다운받기 형식은 날짜+팀+dh+년도+영상번호.mp4\n","        urllib.request.urlretrieve(soup.find('video',id='videoElement')['src'],'c:/data/'+df['date'][i]+df['team'][i]+df['dh'][i]+'2021-'+df['number'][i]+'.mp4')\n","        end=time.time()\n","        print('end: ',end)\n","        print(end-start)\n","    #광고 영상인 경우 용량이 6메가가 안되기 때문에 6메가가 넘는 경우에만 다음으로 진행\n","    if os.path.getsize('c:/data/'+df['date'][i]+df['team'][i]+df['dh'][i]+'2021-'+df['number'][i]+'.mp4')>6000000:\n","        t=0\n","        i+=1\n","    #광고 영상인 경우 대기시간을 50으로 늘려주어 광고를 시청하고나오는 본영상의 src를 얻어올 수 있게 함\n","    #i를 증가시키지 않음으로 방금 진행한 다운로드 과정을 다시 한번 진행(50초 대기)\n","    else:\n","        t=50"],"id":"1e1548c9","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"atv1lpzV1sxH"},"source":["#시작점 끝점 직접입력\n","import urllib.request\n","import webbrowser\n","import os\n","\n","#driver생성\n","driver = webdriver.Chrome(\"c:/data/chromedriver\")#, options=chrome_options)\n","\n","#src가 블롭형식으로 되어있을 때 그 리스트를 받기 위해서 생성\n","blob=pd.DataFrame()\n","\n","#while문을 돌리기위해 i생성(시작점) 직접입력받음\n","i=int(input(\"시작점\"))\n","\n","last=int(input(\"끝점\"))\n","#광고영상이 대신 다운받아지는것을 방지하기 위해 광고일 경우 50초(광고시간)를 기다렸다가 진행\n","t=0\n","\n","#i가 df의 길이 만큼 반복\n","while i < last+1:\n","    print(i)\n","    #df의 site칼럼에서 url받기\n","    baseUrl = df['site'][i]\n","    #driver실행\n","    driver.get(baseUrl)\n","    soup = BeautifulSoup(driver.page_source, \"html\")\n","    #실행된 site에서 영상 부분 태그\n","    v_url=soup.find('iframe',id='player_vod')['src']\n","    #주소에서 화질 변경 HIGH는 720 HIGH4는 1080\n","    v_url=v_url.replace('HIGH','HIGH4')\n","    #driver실행\n","    driver.get(v_url)\n","    #바로 src를 얻어오면 src가 생성이 되어있지않기 때문에 src가 생성될 수 있게 대기\n","    time.sleep(3)\n","    soup = BeautifulSoup(driver.page_source, \"html\")  \n","    #광고영상이 나오는 url인 경우 50초를 기다리고 아닌 경우 0초\n","    time.sleep(t)\n","    #src가 blob으로 되어있는 경우 blob df에 넣기 \n","    if 'blob' in soup.find('video',id='videoElement')['src']:\n","        blob=blob.append(df.loc[i])\n","    else:\n","        #print(soup.find('video',id='videoElement')['src'])\n","        start=time.time()\n","        print('start: ',start)\n","        #파일 다운받기 형식은 날짜+팀+dh+년도+영상번호.mp4\n","        urllib.request.urlretrieve(soup.find('video',id='videoElement')['src'],'c:/data/'+df['date'][i]+df['team'][i]+df['dh'][i]+'2021-'+df['number'][i]+'.mp4')\n","        end=time.time()\n","        print('end: ',end)\n","        print(end-start)\n","    #광고 영상인 경우 용량이 6메가가 안되기 때문에 6메가가 넘는 경우에만 다음으로 진행\n","    if os.path.getsize('c:/data/'+df['date'][i]+df['team'][i]+df['dh'][i]+'2021-'+df['number'][i]+'.mp4')>6000000:\n","        t=0\n","        i+=1\n","    #광고 영상인 경우 대기시간을 50으로 늘려주어 광고를 시청하고나오는 본영상의 src를 얻어올 수 있게 함\n","    #i를 증가시키지 않음으로 방금 진행한 다운로드 과정을 다시 한번 진행(50초 대기)\n","    else:\n","        t=50"],"id":"atv1lpzV1sxH","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t-s0zEbA3vhi"},"source":["#이미 다운 받아놓은 영상 중 광고영상이 있을 경우 다시 다운받게 해주는 코드\n","\n","driver = webdriver.Chrome(\"c:/data/chromedriver\")\n","#src가 블롭형식으로 되어있을 때 그 리스트를 받기 위해서 생성\n","blob=pd.DataFrame()\n","#i를 0으로 초기화 시작점\n","i=0\n","#임의로 201로 지정해놓았지만 변경가능 끝점\n","while i < 201:\n","    #6메가가 안넘을 경우 광고이기 때문에 50초를 기다렸다가 제대로된 src가 나오면 다운받기\n","    if os.path.getsize(df['date'][i]+df['team'][i]+df['dh'][i]+'2021-'+df['number'][i]+'.mp4')<6000000:\n","        baseUrl = df['site'][i]\n","        driver.get(baseUrl)\n","        soup = BeautifulSoup(driver.page_source, \"html\")\n","        v_url=soup.find('iframe',id='player_vod')['src']\n","        v_url=v_url.replace('HIGH','HIGH4')\n","        driver.get(v_url)\n","        time.sleep(3)\n","        soup = BeautifulSoup(driver.page_source, \"html\")  \n","        time.sleep(50) \n","        if 'blob' in soup.find('video',id='videoElement')['src']:\n","            blob=blob.append(df.loc[i])\n","        else:\n","            print(soup.find('video',id='videoElement')['src'])\n","            start=time.time()\n","            print('start: ',start)\n","            urllib.request.urlretrieve(soup.find('video',id='videoElement')['src'],df['date'][i]+df['team'][i]+df['dh'][i]+'2021-'+df['number'][i]+'.mp4')\n","            end=time.time()\n","            print('end: ',end)\n","            print(end-start)\n","    #i를 1증가시킨후 다시 반복\n","    i+=1"],"id":"t-s0zEbA3vhi","execution_count":null,"outputs":[]}]}